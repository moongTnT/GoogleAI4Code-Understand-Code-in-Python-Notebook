{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":0,"status":"ok","timestamp":1658496923396,"user":{"displayName":"조문근","userId":"14792891422128059653"},"user_tz":-540},"id":"kYwx407r432G"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n","\u001b[K     |████████████████████████████████| 4.4 MB 14.3 MB/s \n","\u001b[K     |████████████████████████████████| 101 kB 12.4 MB/s \n","\u001b[K     |████████████████████████████████| 596 kB 86.4 MB/s \n","\u001b[K     |████████████████████████████████| 6.6 MB 61.8 MB/s \n","\u001b[?25hFri Jul 22 13:35:19 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   35C    P0    24W / 300W |      0MiB / 16160MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","!pip install -q transformers\n","\n","!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"code","colab":{"base_uri":"https://localhost:8080/"},"id":"xCbWRTPs49T0","outputId":"5bd33055-83ad-4df5-d3cf-191b0789f1d7"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/NLP/ENG/ai4code/src2\n"]}],"source":["#@title 기본 제목 텍스트\n","%cd /content/drive/MyDrive/NLP/ENG/ai4code/src2\n","\n","import easydict\n","import gc\n","import torch\n","\n","import pandas as pd\n","from dataset import data_setup\n","\n","from preprocessor import _20CodeCellPreprocessor\n","from train import train, train_setup\n","from util import debug_setup\n","\n","\n","def main():\n","    args = {\n","        'model_name_or_path':'microsoft/codebert-base',\n","        'input_path':'../input/',\n","        'train_path':'./data/train.csv',\n","        'train_mark_path':'./data/train_mark.csv',\n","        'train_features_path':'./data/train_fts.json',\n","        'val_path':\"./data/val.csv\",\n","        'val_mark_path':'./data/val_mark.csv',\n","        'val_features_path':'./data/val_fts.json',\n","        'output_path':'./output',\n","        'md_max_len':64,\n","        'total_max_len':512,\n","        'batch_size':8,\n","        'accumulation_steps':4,\n","        'epoch':0,\n","        'epochs':5,\n","        'n_workers':8,\n","        'debug':True,\n","        'load_train':False,\n","        'max_lr':3e-5,\n","        'min_lr':.3e-6\n","        }\n","    args = easydict.EasyDict(args)\n","\n","    preprocessor = _20CodeCellPreprocessor(**vars(args))\n","    train_df, val_df, train_df_mark, val_df_mark, train_fts, val_fts = preprocessor.run()\n","\n","    print('before debug', train_df.shape, val_df.shape,\n","          train_df_mark.shape, val_df_mark.shape, len(train_fts), len(val_fts))\n","\n","    if args.debug:\n","        train_df, train_df_mark, train_fts, val_df, val_df_mark, val_fts = debug_setup(\n","            train_df, train_df_mark, train_fts, val_df, val_df_mark, val_fts)\n","\n","    print('after debug', train_df.shape, val_df.shape,\n","          train_df_mark.shape, val_df_mark.shape, len(train_fts), len(val_fts))\n","\n","    train_loader, val_loader = data_setup(train_df_mark, val_df_mark, train_fts, val_fts, args)\n","\n","    df_orders = pd.read_csv(args.input_path + 'train_orders.csv', index_col='id', squeeze=True).str.split()\n","\n","    del train_df, train_df_mark, val_df_mark, train_fts, val_fts, preprocessor\n","    gc.collect()\n","\n","    # This is variable\n","    args.num_train_steps = len(train_loader) / args.accumulation_steps\n","\n","    model, optimizer, scheduler, scaler = train_setup(args)\n","\n","    if args.load_train:\n","        checkpoint = torch.load(args.checkpoint_path)\n","        epoch = checkpoint['epoch']\n","        model.load_state_dict(checkpoint['model_state_dict'])\n","\n","        model.cuda()\n","\n","        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n","        scaler.load_state_dict(checkpoint['scaler_state_dict'])\n","    else:\n","        model.cuda()\n","\n","    train(model, train_loader, val_loader, optimizer,\n","          scheduler, scaler, val_df, df_orders, args)\n","\n","if __name__ == '__main__':\n","    main()\n"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNk6KAKQM6aopOvI9/hbiIi","collapsed_sections":[],"machine_shape":"hm","name":"codebert-base-20samples-cosineannealingwarmuprestarts-max3e5-min3e6-step-len(train_loader)/accumulation_steps.ipynb","version":""},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}