{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import easydict\n",
    "import gc\n",
    "import pandas as pd\n",
    "\n",
    "from preprocessor import PairwisePreprocessor, _20CodeCellPreprocessor\n",
    "from dataset import _20SampleDataset, PairwiseDataset, _20sample_data_setup, pairwise_data_setup\n",
    "from train import pairwise_train_setup, train_setup\n",
    "from util import pairwise_debug_setup, _20sample_debug_setup\n",
    "from metrics import kendall_tau\n",
    "from train import train\n",
    "\n",
    "args = {\n",
    "    'model_name_or_path': 'microsoft/graphcodebert-base',\n",
    "\n",
    "    'input_path': '../input/',\n",
    "\n",
    "    'train_path': './data/train.csv',\n",
    "    'train_mark_path': './data/train_mark.csv',\n",
    "    'train_features_path': './data/train_fts.json',\n",
    "\n",
    "    'val_path': \"./data/val.csv\",\n",
    "    'val_mark_path': './data/val_mark.csv',\n",
    "    'val_features_path': './data/val_fts.json',\n",
    "\n",
    "    'output_path': './output-graphcodebert-20sample-es-cos-dropout-debug',\n",
    "\n",
    "    'md_max_len': 64,\n",
    "    'total_max_len': 512,\n",
    "    'batch_size': 32,\n",
    "    'accumulation_steps': 1,\n",
    "    'epoch': 3,\n",
    "    'epochs': 5,\n",
    "    'n_workers': 8,\n",
    "    'debug': False,\n",
    "    'load_train': False,\n",
    "    'max_lr': 3e-5,\n",
    "    'min_lr': .3e-6,\n",
    "    'kfold': True\n",
    "}\n",
    "\n",
    "args = easydict.EasyDict(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df, val_df are already exits\n",
      "train_fts, val_fts are already exists\n"
     ]
    }
   ],
   "source": [
    "preprocessor = _20CodeCellPreprocessor(**vars(args))\n",
    "train_df, val_df, train_df_mark, val_df_mark, train_fts, val_fts = preprocessor.run()\n",
    "\n",
    "# print('before debug', train_df.shape, val_df.shape, train_df_mark.shape, val_df.shape, len(train_fts), len(val_fts))\n",
    "\n",
    "# kfolds = []\n",
    "# if args.debug:\n",
    "#     for i in range(5):\n",
    "#         fold = _20sample_debug_setup(train_df, train_df_mark, train_fts, val_df, val_df_mark, val_fts)\n",
    "#         kfolds.append(fold)\n",
    "    \n",
    "# train_df, train_df_mark, train_fts, val_df, val_df_mark, val_fts = kfolds[0]\n",
    "# print('after debug', train_df.shape, val_df.shape, train_df_mark.shape, val_df.shape, len(train_fts), len(val_fts))\n",
    "\n",
    "# train_df, train_df_mark, train_fts, val_df, val_df_mark, val_fts = kfolds[1]\n",
    "# print('after debug', train_df.shape, val_df.shape, train_df_mark.shape, val_df.shape, len(train_fts), len(val_fts))\n",
    "\n",
    "# train_df, train_df_mark, train_fts, val_df, val_df_mark, val_fts = kfolds[2]\n",
    "# print('after debug', train_df.shape, val_df.shape, train_df_mark.shape, val_df.shape, len(train_fts), len(val_fts))\n",
    "\n",
    "# train_df, train_df_mark, train_fts, val_df, val_df_mark, val_fts = kfolds[3]\n",
    "# print('after debug', train_df.shape, val_df.shape, train_df_mark.shape, val_df.shape, len(train_fts), len(val_fts))\n",
    "\n",
    "# train_df, train_df_mark, train_fts, val_df, val_df_mark, val_fts = kfolds[4]\n",
    "# print('after debug', train_df.shape, val_df.shape, train_df_mark.shape, val_df.shape, len(train_fts), len(val_fts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ansrm\\AppData\\Local\\Temp\\ipykernel_13768\\2808593356.py:1: FutureWarning: The squeeze argument has been deprecated and will be removed in a future version. Append .squeeze(\"columns\") to the call to squeeze.\n",
      "\n",
      "\n",
      "  df_orders = pd.read_csv(args.input_path + 'train_orders.csv',\n"
     ]
    }
   ],
   "source": [
    "df_orders = pd.read_csv(args.input_path + 'train_orders.csv',\n",
    "                        index_col='id',\n",
    "                        squeeze=True).str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/graphcodebert-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at microsoft/graphcodebert-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\ansrm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss: 0.0981 lr: [3e-05, 3e-05]: 100%|██████████| 60941/60941 [6:22:04<00:00,  2.66it/s]                                     \n",
      "100%|██████████| 6749/6749 [13:21<00:00,  8.42it/s]\n",
      "Preds score 0.8397768916698124\n",
      "Epoch 5 Loss: 0.1134 lr: [2.565053570062023e-05, 2.565053570062023e-05]: 100%|██████████| 60941/60941 [6:21:31<00:00,  2.66it/s]    \n",
      "100%|██████████| 6749/6749 [13:23<00:00,  8.40it/s]\n",
      "Preds score 0.8442684377372627\n",
      "Epoch 6 Loss: 0.0962 lr: [1.515e-05, 1.515e-05]: 100%|██████████| 60941/60941 [6:19:53<00:00,  2.67it/s]                            \n",
      "100%|██████████| 6749/6749 [13:19<00:00,  8.44it/s]\n",
      "Preds score 0.8499189849500974\n",
      "Epoch 7 Loss: 0.0865 lr: [4.64946429937977e-06, 4.64946429937977e-06]: 100%|██████████| 60941/60941 [6:18:38<00:00,  2.68it/s]      \n",
      "100%|██████████| 6749/6749 [13:21<00:00,  8.42it/s]\n",
      "Preds score 0.8526143515753599\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[WinError 433] 없는 장치를 지정했습니다: './output-graphcodebert-20sample-es-cos-dropout-debug'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32mg:\\내 드라이브\\NLP\\ENG\\ai4code\\src2\\graphcodebert-20samples-es-cos-awp-dropout.ipynb 셀 4\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/%EB%82%B4%20%EB%93%9C%EB%9D%BC%EC%9D%B4%EB%B8%8C/NLP/ENG/ai4code/src2/graphcodebert-20samples-es-cos-awp-dropout.ipynb#ch0000003?line=9'>10</a>\u001b[0m model\u001b[39m.\u001b[39mload_state_dict(torch\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39m./output-graphcodebert-20sample-es-cos-dropout-debug/model_epoch_2_0.8441190203208906.bin\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/%EB%82%B4%20%EB%93%9C%EB%9D%BC%EC%9D%B4%EB%B8%8C/NLP/ENG/ai4code/src2/graphcodebert-20samples-es-cos-awp-dropout.ipynb#ch0000003?line=10'>11</a>\u001b[0m model\u001b[39m.\u001b[39mcuda()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/g%3A/%EB%82%B4%20%EB%93%9C%EB%9D%BC%EC%9D%B4%EB%B8%8C/NLP/ENG/ai4code/src2/graphcodebert-20samples-es-cos-awp-dropout.ipynb#ch0000003?line=12'>13</a>\u001b[0m train(model, train_loader, val_loader, optimizer, scheduler, scaler, val_df, df_orders, args)\n",
      "File \u001b[1;32mg:\\내 드라이브\\NLP\\ENG\\ai4code\\src2\\train.py:83\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, val_loader, optimizer, scheduler, scaler, val_df, df_orders, args)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mPreds score\u001b[39m\u001b[39m\"\u001b[39m, preds_score)\n\u001b[0;32m     82\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(args\u001b[39m.\u001b[39moutput_path):\n\u001b[1;32m---> 83\u001b[0m     os\u001b[39m.\u001b[39;49mmkdir(args\u001b[39m.\u001b[39;49moutput_path)\n\u001b[0;32m     85\u001b[0m torch\u001b[39m.\u001b[39msave(model\u001b[39m.\u001b[39mstate_dict(), args\u001b[39m.\u001b[39moutput_path \u001b[39m+\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m/model_epoch_\u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mpreds_score\u001b[39m}\u001b[39;00m\u001b[39m.bin\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 433] 없는 장치를 지정했습니다: './output-graphcodebert-20sample-es-cos-dropout-debug'"
     ]
    }
   ],
   "source": [
    "# for i in range(5):\n",
    "#     train_df, train_df_mark, train_fts, val_df, val_df_mark, val_fts = kfolds[i]\n",
    "import torch\n",
    "\n",
    "train_loader, val_loader = _20sample_data_setup(train_df_mark, val_df_mark, train_fts, val_fts, args)\n",
    "\n",
    "args.num_train_steps = args.epochs * len(train_loader) / args.accumulation_steps\n",
    "\n",
    "model, optimizer, scheduler, scaler = train_setup(args)\n",
    "model.load_state_dict(torch.load('./output-graphcodebert-20sample-es-cos-dropout-debug/model_epoch_2_0.8441190203208906.bin'))\n",
    "model.cuda()\n",
    "\n",
    "train(model, train_loader, val_loader, optimizer, scheduler, scaler, val_df, df_orders, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d49c3f6d6dd49f9272b571d9fad348ab55b8c6c3f691520d74ed0af1f69c3dd8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
